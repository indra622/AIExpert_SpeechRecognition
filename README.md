# AIExpert_SpeechRecognition

![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)
![nVIDIA](https://img.shields.io/badge/nVIDIA-%2376B900.svg?style=for-the-badge&logo=nVIDIA&logoColor=white)
![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![Markdown](https://img.shields.io/badge/markdown-%23000000.svg?style=for-the-badge&logo=markdown&logoColor=white)
![Colab](https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&logo=googlecolab&color=525252)

> Nemo를 사용한 end-to-end ASR fine-tuning

본 실습 자료는 Google Colab 환경을 가정하고 작성됨


# Reference

- [LibriSpeech corpus](http://openslr.org/12/)

- [Zeroth_Korean corpus](http://openslr.org/40/)

- [HuggingFace LibriSpeech dataset](https://huggingface.co/datasets/kresnik/librispeech_asr_test)

- [HuggingFace Zeroth_Korean dataset](https://huggingface.co/datasets/kresnik/zeroth_korean)

- [HugginFace fine-tuned Wav2Vec2.0 Korean](https://huggingface.co/kresnik/wav2vec2-large-xlsr-korean)

- [Nemo Pretrained Model](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_en_conformer_ctc_large_ls)
