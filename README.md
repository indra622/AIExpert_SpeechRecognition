# AIExpert_SpeechRecognition

![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)
![nVIDIA](https://img.shields.io/badge/nVIDIA-%2376B900.svg?style=for-the-badge&logo=nVIDIA&logoColor=white)
![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![Markdown](https://img.shields.io/badge/markdown-%23000000.svg?style=for-the-badge&logo=markdown&logoColor=white)
![Colab](https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&logo=googlecolab&color=525252)

> Nemo와 k2를 사용한 WFST 기반 End-to-end ASR + language model decoding

본 실습 자료는 Google Colab 환경을 가정하고 작성됨


# Reference

- [LibriSpeech corpus](http://openslr.org/12/)

- [LibriSpeech LM](http://openslr.org/11/)

- [HuggingFace LibriSpeech dataset](https://huggingface.co/datasets/kresnik/librispeech_asr_test)

- [Nemo Pretrained Model](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_en_conformer_ctc_large_ls)
